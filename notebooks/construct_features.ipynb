{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "1. Wrap up one function for feature generation \n",
    "2. Wrap up one function for model training \n",
    "3. Within the submission API, consider proper concat of cache and new test \n",
    "    \n",
    "    * V1 features are row-based --> don't need cache. \n",
    "    * V2 features are based on sec_in_bucket (cross-section feat) --> don't need cache. (Perhaps the gen_v2_features function should be changed to not using groupby() ? )\n",
    "    * V3 features requires timeseries data -->  the cache is needed.\n",
    "    * The cache should save the timeseries records of all stocks with sufficient length. \n",
    "    * The row after concat should be re-ordered. \n",
    "    * After calculate features, only the current seconds_in_bucket should be returned. \n",
    "    * Standarization: in the training phase, the standarization is implemented on a multi-day scale. In the cached dataset, only limited timesteps are used in Standarization. \n",
    "    * Standarization: during training, perhaps we should perform Standarization on cross-section only. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import talib as ta\n",
    "from itertools import combinations\n",
    "import seaborn as sns\n",
    "import os, sys, warnings\n",
    "from time import time \n",
    "from create_feature import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "df = df[~df['target'].isnull()] \n",
    "\n",
    "print(df.shape)\n",
    "print(f\"Trading days: {df['date_id'].nunique()}\")\n",
    "print(f\"Stocks: {df['stock_id'].nunique()}\")\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dicts = {\n",
    "    'prices': [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"],\n",
    "    'sizes':  [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"],\n",
    "    \"category\": [\"stock_id\", \"seconds_in_bucket\", 'imbalance_buy_sell_flag']\n",
    "    }\n",
    "\n",
    "df_final, feature_dicts = gen_features(df, feature_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final.to_csv(\"/home/lishi/projects/Competition/kaggle_2023/data/train_full_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import joblib, gc\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set lgb parameters\n",
    "lgb_params = {\n",
    "    'learning_rate': 0.009,#0.018,\n",
    "    'max_depth': 10,#9,\n",
    "    'n_estimators': 700,#600,\n",
    "    'num_leaves': 500,#440,\n",
    "    'objective': 'mae',\n",
    "    'random_state': 42,\n",
    "    'reg_alpha': 0.01,\n",
    "    'reg_lambda': 0.01,\n",
    "    'early_stopping_rounds': 50,\n",
    "    'num_threads': 24\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = []\n",
    "category_cols = []\n",
    "\n",
    "for k, v in feature_dicts.items():\n",
    "    print(k, len(v))\n",
    "    feature_cols += v\n",
    "    if k in ['category', 'v1_feature_category']:\n",
    "        category_cols += v\n",
    "    \n",
    "print(len(feature_cols))\n",
    "print(len(category_cols))\n",
    "\n",
    "scale_cols = [x for x in feature_cols if x not in category_cols]\n",
    "scaler = StandardScaler()\n",
    "scaler_train = scaler.fit(df_final[scale_cols])\n",
    "df_final[scale_cols] = scaler_train.transform(df_final[scale_cols])\n",
    "\n",
    "scaler_filename = \"../data/scaler.save\"\n",
    "joblib.dump(scaler_train, scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV strategy: KFold\n",
    "# split train and valid set by date_id\n",
    "# Within each fold, a continuous period of n days is used as validation set\n",
    "# The start date of validation set is shifted by n day for each fold\n",
    "# n = total_days / n_fold\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=False, random_state=None)\n",
    "kf_split = k_fold.split(df['date_id'].unique())\n",
    "\n",
    "mae_scores = []\n",
    "models = []\n",
    "\n",
    "for fold, (train_dates, valid_dates) in enumerate(kf_split):\n",
    "    \n",
    "    print(f\"Fold {fold+1}\")\n",
    "    fold_start = time()\n",
    "    \n",
    "    # split train and valid set\n",
    "    df_train = df_final[df_final[\"date_id\"].isin(train_dates)]\n",
    "    df_valid = df_final[df_final[\"date_id\"].isin(valid_dates)]\n",
    "    \n",
    "    print(f\"Train : {df_train.shape}, Valid : {df_valid.shape}\")\n",
    "    \n",
    "    df_train_feature = df_train[feature_cols]\n",
    "    df_valid_feature = df_valid[feature_cols]\n",
    "    \n",
    "    print(f\"Train feature: {df_train_feature.shape}, Train target: {df_train['target'].shape}\")\n",
    "    print(f\"Valid feature: {df_valid_feature.shape}, Valid target: {df_valid['target'].shape}\")\n",
    "    \n",
    "    # train_data = lgb.Dataset(\n",
    "    #     data=x_train, \n",
    "    #     label=y_train, \n",
    "    #     feature_name=feature_names,\n",
    "    #     categorical_feature=categorical_cols\n",
    "    #     )\n",
    "    \n",
    "    # valid_data = lgb.Dataset(\n",
    "    #     data=x_valid, \n",
    "    #     label=y_valid, \n",
    "    #     feature_name=feature_names,\n",
    "    #     categorical_feature=categorical_cols\n",
    "    #     )\n",
    "    \n",
    "    print(f\"Data preparation finished. Time elapsed: {time()-fold_start:.2f}s\")\n",
    "    \n",
    "    print(\"Start training...\")\n",
    "    training_start = time()\n",
    "    \n",
    "    # model = lgb.train(lgb_params, train_data, valid_sets=[train_data, valid_data])\n",
    "    lgb_model = lgb.LGBMRegressor(**lgb_params)\n",
    "    \n",
    "    lgb_model.fit(\n",
    "        df_train_feature, \n",
    "        df_train['target'],\n",
    "        eval_set=[(df_valid_feature, df_valid['target'])],\n",
    "        feature_name = feature_cols,\n",
    "        categorical_feature = category_cols,\n",
    "        callbacks=[\n",
    "            lgb.callback.early_stopping(stopping_rounds=100),\n",
    "            lgb.callback.log_evaluation(period=100),\n",
    "            ],\n",
    "        )\n",
    "    \n",
    "    models.append(lgb_model)\n",
    "    \n",
    "    model_file = f\"../data/lgb_regressor_fold_{fold+1}.pkl\" \n",
    "    joblib.dump(lgb_model, model_file)\n",
    "    \n",
    "    print(f\"Fold {fold+1} Trainning finished. Time elapsed: {time()-training_start:.2f}s\")\n",
    "    \n",
    "    y_pred_valid = lgb_model.predict(df_valid_feature)\n",
    "    print(y_pred_valid)\n",
    "    mae = mean_absolute_error(df_valid['target'], y_pred_valid)\n",
    "    mae_scores.append(mae)\n",
    "\n",
    "    print(f\"Fold {fold+1} MAE: {mae}\")\n",
    "    print(f\"Fold {fold+1} Time elapsed: {time()-fold_start:.2f}s\")\n",
    "    \n",
    "    del df_train, df_valid, df_train_feature, df_valid_feature\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"Overall MAE: {np.mean(mae_scores)}\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "# add path of optiver2023 package to pythonpath \n",
    "sys.path.append(os.path.abspath('../data'))\n",
    "\n",
    "import optiver2023 \n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n",
    "counter = 0 \n",
    "max_ts_len = 12 # max length of ts to keep in cache\n",
    "\n",
    "n_reveals = 0\n",
    "\n",
    "feature_dicts = {\n",
    "    'prices': [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"],\n",
    "    'sizes':  [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"],\n",
    "    \"category\": [\"stock_id\", \"seconds_in_bucket\", 'imbalance_buy_sell_flag']\n",
    "}\n",
    "\n",
    "cache = pd.DataFrame()\n",
    "df_records = pd.DataFrame()\n",
    "\n",
    "day_begin = time()\n",
    "\n",
    "model_files = glob(\"../data/lgb_regressor_fold_*.pkl\")\n",
    "models = [joblib.load(model_file) for model_file in model_files]\n",
    "\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "    \n",
    "    now_time = time()\n",
    "    \n",
    "    current_sec = test['seconds_in_bucket'].unique()\n",
    "\n",
    "    test = test.fillna(0)\n",
    "    test = reduce_mem_usage(test, verbose=0)\n",
    "    \n",
    "    df_v1, v1_feat, v1_feat_cat = gen_v1_features(test, feature_dicts['prices'])\n",
    "    feature_dicts['v1_features'] = v1_feat\n",
    "    feature_dicts['v1_feature_category'] = v1_feat_cat\n",
    "    \n",
    "    v2_feat_cols = feature_dicts['prices'] + feature_dicts['sizes'] + feature_dicts['v1_features']\n",
    "    df_v2, v2_features = gen_v2_features(df_v1, v2_feat_cols)\n",
    "    feature_dicts['v2_features'] = v2_features\n",
    "    \n",
    "    cache = pd.concat([cache, df_v2])\n",
    "    cache.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # In cache, we keep only the past max_ts_len seconds of data\n",
    "    if counter > max_ts_len:\n",
    "        sec_in_buk_list = cache['seconds_in_bucket'].unique()\n",
    "        sec_in_buk_list.sort()\n",
    "        sec_to_keep = sec_in_buk_list[-max_ts_len:]\n",
    "        cache = cache[cache['seconds_in_bucket'].isin(sec_to_keep)]\n",
    "        cache.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "    df_v3, v3_features = gen_v3_features(\n",
    "        cache, \n",
    "        feature_dicts['prices'],\n",
    "        feature_dicts['sizes'],\n",
    "        feature_dicts['v1_features']\n",
    "        )\n",
    "    \n",
    "    feature_dicts['v3_features'] = v3_features\n",
    "    \n",
    "    df_v3.fillna(0, inplace=True)\n",
    "    df_v3.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    df_v3 = reduce_mem_usage(df_v3, verbose=0)\n",
    "    \n",
    "    df_test = df_v3[df_v3['seconds_in_bucket'].isin(current_sec)]\n",
    "    df_records = pd.concat([df_records, df_test])\n",
    "    \n",
    "    feature_cols = []\n",
    "    category_cols = []\n",
    "\n",
    "    for k, v in feature_dicts.items():\n",
    "        print(k, len(v))\n",
    "        feature_cols += v\n",
    "        if k in ['category', 'v1_feature_category']:\n",
    "            category_cols += v\n",
    "        \n",
    "    print(len(feature_cols))\n",
    "    print(len(category_cols))\n",
    "\n",
    "    scale_cols = [x for x in feature_cols if x not in category_cols]\n",
    "    \n",
    "    df_test = df_test[feature_cols]\n",
    "    df_test[scale_cols] = scaler_train.transform(df_test[scale_cols])\n",
    "    print(df_test.shape)\n",
    "    \n",
    "    # predict target using trained model\n",
    "    target = 0\n",
    "    for model in models:\n",
    "        target += model.predict(df_test) \n",
    "        \n",
    "    target /= len(models)\n",
    "    \n",
    "    sample_prediction['target'] = target\n",
    "    \n",
    "    env.predict(sample_prediction)\n",
    "\n",
    "    # after 54 timesteps, a new day starts\n",
    "    if counter >= 54:\n",
    "        print(f\"New Day! Time used: {time() - day_begin:2f}s.\")\n",
    "        counter = 0\n",
    "        day_begin = time()\n",
    "    else:\n",
    "        counter += 1\n",
    "        \n",
    "    if counter == 1:\n",
    "        n_reveals += 1        \n",
    "        print('Targets revealed for day', revealed_targets['revealed_date_id'].unique().tolist())\n",
    "        if n_reveals > 1:\n",
    "            df_records.merge(\n",
    "                revealed_targets, \n",
    "                left_on=['date_id', 'stock_id', 'seconds_in_bucket'],\n",
    "                right_on=['revealed_date_id', 'stock_id', 'seconds_in_bucket'], \n",
    "                how='left')\n",
    "            print(df_records.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any missing values or infinite values\n",
    "# check_invalid_values = pd.DataFrame(columns=['null', 'inf'])\n",
    "# for col in df.columns:\n",
    "#     try:\n",
    "#         check_invalid_values.loc[col] = [df[col].isnull().sum(), np.isinf(df[col]).sum()]\n",
    "#     except:\n",
    "#         print(\"Skip column: \", col)\n",
    "#         pass\n",
    "    \n",
    "# check_invalid_values.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mae scores\n",
    "plt.figure(figsize=(6, 5))\n",
    "\n",
    "plt.plot(mae_scores, marker='o', color='blue', label='MAE')\n",
    "plt.text(0.95, 0.95, f\"Overall MAE: {np.mean(mae_scores):.4f}\", fontsize=12, ha='right', va='top', color='red', transform=plt.gca().transAxes)\n",
    "plt.title('MAE Scores')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('MAE')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance using Gain\n",
    "# fig = plt.figure()\n",
    "# lgb.plot_importance(model, importance_type=\"gain\", title=\"LightGBM Feature Importance (Gain)\")\n",
    "# plt.show()\n",
    "feature_imp = pd.DataFrame({'Value':lgb_model.feature_importances_,'Feature':feature_cols})\n",
    "feature_imp.sort_values(by='Value', ascending=False, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(8, 16))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.iloc[2:])\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp.shape[0] * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV strategy: KFold\n",
    "# split train and valid set by date_id\n",
    "# Within each fold, a continuous period of n days is used as validation set\n",
    "# The start date of validation set is shifted by n day for each fold\n",
    "# n = total_days / n_fold\n",
    "\n",
    "# remove the least important features (based on feature importance)\n",
    "remove_features = feature_imp.iloc[-10:].Feature.tolist()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=False, random_state=None)\n",
    "kf_split = k_fold.split(df['date_id'].unique())\n",
    "\n",
    "mae_scores = []\n",
    "models = []\n",
    "\n",
    "feature_names = [x for x in categorical_cols + feature_cols if x not in remove_features]\n",
    "feature_cols_less = [x for x in feature_cols if x not in remove_features]\n",
    "categorical_cols_less = [x for x in categorical_cols if x not in remove_features]\n",
    "\n",
    "print(f\"Length of feature names: {len(feature_names)}\")\n",
    "\n",
    "for fold, (train_dates, valid_dates) in enumerate(kf_split):\n",
    "    \n",
    "    print(f\"Fold {fold+1}\")\n",
    "    fold_start = time()\n",
    "    \n",
    "    # split train and valid set\n",
    "    df_train = df[df[\"date_id\"].isin(train_dates)]\n",
    "    df_valid = df[df[\"date_id\"].isin(valid_dates)]\n",
    "    \n",
    "    print(f\"Train : {df_train.shape}, Valid : {df_valid.shape}\")\n",
    "    \n",
    "    df_train_feature = df_train[feature_names]\n",
    "    df_train_feature = standardize(df_train_feature, feature_cols_less)\n",
    "    \n",
    "    print(f\"Train feature: {x_train.shape}, Train target: {y_train.shape}\")\n",
    "    \n",
    "    df_valid_feature = df_valid[feature_names]\n",
    "    df_valid_feature = standardize(df_valid_feature, feature_cols_less)\n",
    "    \n",
    "    print(f\"Valid feature: {x_valid.shape}, Valid target: {y_valid.shape}\")\n",
    "    \n",
    "    print(f\"Data preparation finished. Time elapsed: {time()-fold_start:.2f}s\")\n",
    "    \n",
    "    print(\"Start training...\")\n",
    "    training_start = time()\n",
    "    \n",
    "    # model = lgb.train(lgb_params, train_data, valid_sets=[train_data, valid_data])\n",
    "    lgb_model = lgb.LGBMRegressor(**lgb_params)\n",
    "    lgb_model.fit(\n",
    "        df_train_feature, \n",
    "        df_train['target'],\n",
    "        eval_set=[(df_valid_feature, df_valid['target'])],\n",
    "        feature_name = feature_names,\n",
    "        categorical_feature = categorical_cols_less,\n",
    "        callbacks=[\n",
    "            lgb.callback.early_stopping(stopping_rounds=100),\n",
    "            lgb.callback.log_evaluation(period=100),\n",
    "            ],\n",
    "        )\n",
    "    \n",
    "    models.append(lgb_model)\n",
    "    \n",
    "    model_file = f\"../data/lgb_regressor_fold_{fold+1}_feat_400.pkl\" \n",
    "    joblib.dump(lgb_model, model_file)\n",
    "    \n",
    "    print(f\"Fold {fold+1} Trainning finished. Time elapsed: {time()-training_start:.2f}s\")\n",
    "    \n",
    "    y_pred_valid = lgb_model.predict(df_valid_feature)\n",
    "    mae = mean_absolute_error(df_valid['target'], y_pred_valid)\n",
    "    mae_scores.append(mae)\n",
    "\n",
    "    print(f\"Fold {fold+1} MAE: {mae}\")\n",
    "    print(f\"Fold {fold+1} Time elapsed: {time()-fold_start:.2f}s\")\n",
    "    \n",
    "    del df_train, df_valid, df_train_feature, df_valid_feature\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"Overall MAE: {np.mean(mae_scores)}\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mae scores\n",
    "plt.figure(figsize=(6, 5))\n",
    "\n",
    "plt.plot(mae_scores, marker='o', color='blue', label='MAE')\n",
    "plt.text(0.95, 0.95, f\"Overall MAE: {np.mean(mae_scores):.4f}\", fontsize=12, ha='right', va='top', color='red', transform=plt.gca().transAxes)\n",
    "plt.title('MAE Scores')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame({'Value':lgb_model.feature_importances_,'Feature':feature_names})\n",
    "feature_imp.sort_values(by='Value', ascending=False, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(8, 16))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.iloc[2:60])\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "\n",
    "# add path of optiver2023 package to pythonpath \n",
    "sys.path.append(os.path.abspath('../data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optiver2023 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_sum(prices, volumes):\n",
    "    std_error = np.sqrt(volumes)\n",
    "    step = np.sum(prices) / np.sum(std_error)\n",
    "    out = prices - std_error * step\n",
    "    return out\n",
    "\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n",
    "counter = 0 \n",
    "\n",
    "y_min, y_max = -64, 64\n",
    "qps, predictions = [], []\n",
    "cache = pd.DataFrame()\n",
    "\n",
    "prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n",
    "sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n",
    "categorical_cols = [\"stock_id\", \"seconds_in_bucket\", 'imbalance_buy_sell_flag']\n",
    "\n",
    "feature_cols = prices + sizes\n",
    "\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "    now_time = time()\n",
    "    \n",
    "    test_len = len(test)\n",
    "    \n",
    "    test, v1_features, v1_feature_category = gen_v1_features(test, prices)\n",
    "    feature_cols += v1_features\n",
    "    categorical_cols += v1_feature_category\n",
    "\n",
    "    test, v2_features = gen_v2_features(test, prices+sizes+v1_features)\n",
    "    feature_cols += v2_features\n",
    "    \n",
    "    cache = pd.concat([cache, test], ignore_index=True, axis=0)\n",
    "    \n",
    "    if counter > 0:\n",
    "        cache = cache.sort_values(['date_id', 'stock_id', 'seconds_in_bucket']).reset_index(drop=True)\n",
    "        dates_unique = cache['date_id'].unique()\n",
    "        cache = cache[cache['date_id'] == dates_unique[-1]].reset_index(drop=True)\n",
    "        print(counter, cache.shape)\n",
    "\n",
    "    cache, v3_features = gen_v3_features(cache, prices, sizes, v1_features)\n",
    "    feature_cols += v3_features \n",
    "\n",
    "    cache.fillna(0, inplace=True)\n",
    "    cache.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "    cache = reduce_mem_usage(cache, verbose=1)\n",
    "    \n",
    "    df_test = cache[-test_len:]\n",
    "    \n",
    "    print(f\"df_test shape: {df_test.shape}\")\n",
    "    print(f\"Feature preprocess done! Time elapsed: {time()-now_time:.2f}s\")\n",
    "    \n",
    "    # lgb_predictions = np.zeros(len(cache))\n",
    "    # for model in models:\n",
    "    #     lgb_predictions +=  model.predict(df_test[feature_cols])\n",
    "\n",
    "    print(len(feature_cols))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple validation split: keep the last 45 days for validation\n",
    "\n",
    "# split_day = 435\n",
    "# df_train = df[df[\"date_id\"] <= split_day]\n",
    "# df_valid = df[df[\"date_id\"] > split_day]\n",
    "# print(f\"Train : {df_train.shape}, Valid : {df_valid.shape}\")\n",
    "\n",
    "# df_train_feature = df_train[categorical_cols + feature_cols]\n",
    "# df_train_target = df_train[\"target\"]\n",
    "\n",
    "# df_valid_feature = df_valid[categorical_cols + feature_cols]\n",
    "# df_valid_target = df_valid[\"target\"]\n",
    "\n",
    "# print(f\"Train feature: {df_train_feature.shape}, Train target: {df_train_target.shape}\")\n",
    "# print(f\"Valid feature: {df_valid_feature.shape}, Valid target: {df_valid_target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, SGD\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feature = standardize(df_train_feature, feature_cols)\n",
    "df_valid_feature = standardize(df_valid_feature, feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a Dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, features, target):\n",
    "        self.y = target\n",
    "        self.X = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx, :], self.y[idx]\n",
    "    \n",
    "    \n",
    "# define a neural network model of 2 layers\n",
    "# first layer is a non-linear layer with m neurons\n",
    "# second layer is a linear layer with n neuron\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        output = self.linear_relu_stack(x)\n",
    "        return output\n",
    "    \n",
    "# define a function to train the model\n",
    "def train(model, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        local_data, local_target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(local_data.float())\n",
    "        loss = criterion(output, local_target.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
    "\n",
    "# define a function for validation\n",
    "def validation(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            local_data, local_target = data.to(device), target.to(device)\n",
    "            output = model(local_data.float())\n",
    "            validation_loss += criterion(output, local_target.float()).item()\n",
    "            y_true.extend(target.tolist())\n",
    "            y_pred.extend(output.tolist())\n",
    "            \n",
    "    validation_loss /= len(val_loader.dataset)\n",
    "    print(f\"\\nValidation set: Average loss: {validation_loss:.6f}\")\n",
    "    print(f\"\\nValidation set: Mean Average Error: {mean_absolute_error(y_true, y_pred):.6f}\\n\")\n",
    "\n",
    "# define a function to predict the target\n",
    "def predict(model, pred_loader):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in pred_loader:\n",
    "            output = model(data.float())\n",
    "            y_pred.extend(output.tolist())\n",
    "            \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(torch.from_numpy(df_train_feature.values), torch.from_numpy(df_train_target.values))\n",
    "valid_dataset = MyDataset(torch.from_numpy(df_valid_feature.values), torch.from_numpy(df_valid_target.values))\n",
    "\n",
    "# print number of data points and number of features\n",
    "print(f\"Number of data points: {train_dataset.X.shape[0]}\")\n",
    "print(f\"Number of features: {train_dataset.X.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(460, 128, 1).to(device)\n",
    "\n",
    "# train the model with train_dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=True)\n",
    "val_loader = DataLoader(valid_dataset, batch_size=2048, shuffle=True)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(1, 3):\n",
    "    train(model, train_loader, optimizer, criterion, epoch)\n",
    "    validation(model, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
