{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57891,"databundleVersionId":7056235,"sourceType":"competition"},{"sourceId":7171303,"sourceType":"datasetVersion","datasetId":4143427},{"sourceId":7171337,"sourceType":"datasetVersion","datasetId":4143450},{"sourceId":7171614,"sourceType":"datasetVersion","datasetId":4143466},{"sourceId":7177871,"sourceType":"datasetVersion","datasetId":4148291}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nprint(\"Current DIR: \", os.getcwd())\n\n# from platform import python_version\n# print(python_version())\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.034342,"end_time":"2023-12-06T09:31:15.433227","exception":false,"start_time":"2023-12-06T09:31:15.398885","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T12:38:38.882353Z","iopub.execute_input":"2023-12-12T12:38:38.882816Z","iopub.status.idle":"2023-12-12T12:38:38.898035Z","shell.execute_reply.started":"2023-12-12T12:38:38.882781Z","shell.execute_reply":"2023-12-12T12:38:38.896513Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Current DIR:  /kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom itertools import combinations\nfrom time import time\n\nimport gc \n\nimport warnings \nwarnings.filterwarnings('ignore')","metadata":{"papermill":{"duration":7.125579,"end_time":"2023-12-06T09:31:23.694741","exception":false,"start_time":"2023-12-06T09:31:16.569162","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T12:38:38.901782Z","iopub.execute_input":"2023-12-12T12:38:38.902405Z","iopub.status.idle":"2023-12-12T12:38:40.186727Z","shell.execute_reply.started":"2023-12-12T12:38:38.902349Z","shell.execute_reply":"2023-12-12T12:38:40.185353Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# print(\"pandas version:\", pd.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T12:38:40.189409Z","iopub.execute_input":"2023-12-12T12:38:40.190314Z","iopub.status.idle":"2023-12-12T12:38:40.198061Z","shell.execute_reply.started":"2023-12-12T12:38:40.190226Z","shell.execute_reply":"2023-12-12T12:38:40.196464Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=0):\n    \"\"\"\n    Iterate through all numeric columns of a dataframe and modify the data type\n    to reduce memory usage.\n    \"\"\"\n    # Calculate the initial memory usage of the DataFrame\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            \n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                # Check if the column's data type is a float\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float32)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float32)\n                    \n    if verbose:\n        print(f\"Memory usage of dataframe is {start_mem:.2f} MB\")\n        end_mem = df.memory_usage().sum() / 1024**2\n        print(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n        decrease = 100 * (start_mem - end_mem) / start_mem\n        print(f\"Decreased by {decrease:.2f}%\")\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-12-12T12:38:40.200841Z","iopub.execute_input":"2023-12-12T12:38:40.201504Z","iopub.status.idle":"2023-12-12T12:38:40.221813Z","shell.execute_reply.started":"2023-12-12T12:38:40.201454Z","shell.execute_reply":"2023-12-12T12:38:40.219984Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def gen_v1_features(df, prices):\n    # V1 features: directly apply formula to a single row\n    \n    v1_features = {\n        \"volume\": \"ask_size + bid_size\",\n        \"mid_price\": \"(ask_price + bid_price)/2\",\n        \"liquidity_imbalance\": \"(bid_size-ask_size)/(bid_size+ask_size)\",\n        \"matched_imbalance\": \"(imbalance_size - matched_size)/(matched_size+imbalance_size)\",\n        \"size_imbalance\": \"bid_size / ask_size\",\n        \"imbalance_intensity\": \"imbalance_size / volume\",\n        \"matched_intensity\": \"matched_size / volume\",\n        \"price_spread\": \"ask_price - bid_price\",\n        'market_urgency': 'price_spread * liquidity_imbalance',\n        'depth_pressure': '(ask_size - bid_size) * (far_price - near_price)',\n        'price_pressure': 'imbalance_size * (ask_price - bid_price)',\n        'imbalance_with_flag': 'imbalance_size * imbalance_buy_sell_flag',\n    }\n\n    # include pair-wise price imbalances\n    for c in combinations(prices, 2):\n        v1_features[f\"{c[0]}_{c[1]}_imbalance\"] = f\"({c[0]} - {c[1]}) / ({c[0]} + {c[1]})\"\n    \n    for k, v in v1_features.items():\n        df[k] = df.eval(v)\n        \n    v1_feature_category = {\n#         'minute': 'seconds_in_bucket // 60',\n        'imb_buy_side': \"(imbalance_buy_sell_flag == 1)\",\n        'imb_sell_side': \"(imbalance_buy_sell_flag == -1)\",\n        'first_half_session': '(seconds_in_bucket <= 240)',\n        'second_half_session': '(seconds_in_bucket > 240)'\n    }\n    \n    for k, v in v1_feature_category.items():\n        df[k] = df.eval(v).astype(np.int8)\n    \n    df['minute'] = df['seconds_in_bucket'] // 60\n        \n    df = reduce_mem_usage(df, verbose=0)\n        \n    return df, list(v1_features.keys()), ['minute']+list(v1_feature_category.keys())","metadata":{"execution":{"iopub.status.busy":"2023-12-12T12:38:40.225057Z","iopub.execute_input":"2023-12-12T12:38:40.225622Z","iopub.status.idle":"2023-12-12T12:38:40.239688Z","shell.execute_reply.started":"2023-12-12T12:38:40.225570Z","shell.execute_reply":"2023-12-12T12:38:40.238524Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def gen_feature_cols(feature_dicts):\n    \n    feature_cols = []\n    category_cols = []\n    \n    for k, v in feature_dicts.items():\n        feature_cols += v\n        if k in ['category', 'v1_feature_category']:\n            category_cols += v\n            \n    return feature_cols, category_cols\n","metadata":{"execution":{"iopub.status.busy":"2023-12-12T12:38:40.241322Z","iopub.execute_input":"2023-12-12T12:38:40.241821Z","iopub.status.idle":"2023-12-12T12:38:40.255549Z","shell.execute_reply.started":"2023-12-12T12:38:40.241785Z","shell.execute_reply":"2023-12-12T12:38:40.254397Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def gen_features_49(df, feature_dicts):\n    \n    df = df.fillna(0)\n    df = reduce_mem_usage(df, verbose=0)\n    \n    df_v1, v1_feat, v1_feat_cat = gen_v1_features(df, feature_dicts['prices'])\n    feature_dicts['v1_features'] = v1_feat\n    feature_dicts['v1_feature_category'] = v1_feat_cat\n    \n    df_v1.fillna(0, inplace=True)\n    df_v1.replace([np.inf, -np.inf], 0, inplace=True)\n    df_v1 = reduce_mem_usage(df_v1, verbose=0)\n    \n    return df_v1, feature_dicts","metadata":{"execution":{"iopub.status.busy":"2023-12-12T12:38:40.257255Z","iopub.execute_input":"2023-12-12T12:38:40.258590Z","iopub.status.idle":"2023-12-12T12:38:40.270870Z","shell.execute_reply.started":"2023-12-12T12:38:40.258528Z","shell.execute_reply":"2023-12-12T12:38:40.268543Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def zero_sum(prices, volumes):\n    std_error = np.sqrt(volumes)\n    step = np.sum(prices) / np.sum(std_error)\n    out = prices - std_error * step\n    return out","metadata":{"execution":{"iopub.status.busy":"2023-12-12T12:38:40.272825Z","iopub.execute_input":"2023-12-12T12:38:40.274042Z","iopub.status.idle":"2023-12-12T12:38:40.282870Z","shell.execute_reply.started":"2023-12-12T12:38:40.273993Z","shell.execute_reply":"2023-12-12T12:38:40.281628Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import optiver2023\n\nenv = optiver2023.make_env()\niter_test = env.iter_test()","metadata":{"papermill":{"duration":0.01316,"end_time":"2023-12-06T09:31:23.712156","exception":false,"start_time":"2023-12-06T09:31:23.698996","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T12:38:40.284445Z","iopub.execute_input":"2023-12-12T12:38:40.284860Z","iopub.status.idle":"2023-12-12T12:38:40.299815Z","shell.execute_reply.started":"2023-12-12T12:38:40.284824Z","shell.execute_reply":"2023-12-12T12:38:40.298341Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"max_ts_len = 12 # max length of ts to keep in cache\n\nfeature_dicts = {\n    'prices': [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"],\n    'sizes':  [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"],\n    \"category\": [\"stock_id\", \"seconds_in_bucket\", 'imbalance_buy_sell_flag']\n}\n\n# load train_csv to prepare df_records and df_revealed\nn_lookback = 50\ntrain_csv = \"/kaggle/input/optiver-trading-at-the-close/train.csv\"\n\ndf = pd.read_csv(train_csv)\ndf = df[~df['target'].isnull()]\n\ndate_list = df['date_id'].unique().tolist()\ndate_list.sort()\n\nlookback = date_list[-n_lookback:]\n\n# generate df_records\ndf_records = df[df['date_id'].isin(lookback)].copy()\ndf_records.drop(columns=['target'], inplace=True)\n\ndf_records, feature_dicts = gen_features_49(df_records, feature_dicts)\n\ndf_records.fillna(0, inplace=True)\ndf_records.replace([np.inf, -np.inf], 0, inplace=True)\ndf_records = reduce_mem_usage(df_records, verbose=1)\ndf_records.reset_index(drop=True, inplace=True)\n\n# generate df_revealed\ndf_revealed = df[['date_id', 'stock_id', 'seconds_in_bucket', 'target']]\ndf_revealed = df_revealed[df_revealed['date_id'].isin(lookback)]\ndf_revealed.reset_index(drop=True, inplace=True)\n\ndel df\ngc.collect()","metadata":{"papermill":{"duration":0.005767,"end_time":"2023-12-06T09:33:13.134434","exception":false,"start_time":"2023-12-06T09:33:13.128667","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T12:38:40.301457Z","iopub.execute_input":"2023-12-12T12:38:40.301835Z","iopub.status.idle":"2023-12-12T12:39:03.023552Z","shell.execute_reply.started":"2023-12-12T12:38:40.301803Z","shell.execute_reply":"2023-12-12T12:39:03.022319Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Memory usage of dataframe is 93.36 MB\nMemory usage after optimization is: 93.36 MB\nDecreased by 0.00%\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"22"},"metadata":{}}]},{"cell_type":"code","source":"counter = 0 \nn_reveals = 0\ny_min, y_max = -64, 64\n\ncache = pd.DataFrame()\n\nxy_train_past = df_records.merge(\n        df_revealed, \n        left_on=['date_id', 'stock_id', 'seconds_in_bucket'],\n        right_on=['date_id', 'stock_id', 'seconds_in_bucket'], \n        how='left')\n\nday_begin = time()\n\nfeature_cols, category_cols = gen_feature_cols(feature_dicts)\n\nfor (test, revealed_targets, sample_prediction) in iter_test:\n    now_time = time()\n    \n    curr_date = test['date_id'].unique().tolist()[0]\n    print(\"curr_date\", curr_date)\n    \n    if counter == 0:\n        print(len(df_records))\n        n_reveals += 1        \n        print('Targets revealed for day', revealed_targets['revealed_date_id'].unique().tolist())\n        if n_reveals > 1:\n            tmp = revealed_targets[['revealed_date_id', 'stock_id', 'seconds_in_bucket', 'revealed_target']]\n            tmp.columns = ['date_id', 'stock_id', 'seconds_in_bucket', 'target']\n            df_revealed = pd.concat([df_revealed, tmp])\n\n        lookback = np.arange(curr_date-n_lookback, curr_date)\n        x_train_past = df_records[df_records['date_id'].isin(lookback)]\n        y_train_past = df_revealed[df_revealed['date_id'].isin(lookback)]\n\n        xy_train_past = x_train_past.merge(\n            y_train_past, \n            left_on=['date_id', 'stock_id', 'seconds_in_bucket'],\n            right_on=['date_id', 'stock_id', 'seconds_in_bucket'], \n            how='left')\n        xy_train_past = xy_train_past[~xy_train_past['target'].isnull()]\n    \n    # train knn \n    scaler = StandardScaler()\n    neigh = KNeighborsRegressor(n_neighbors=50, weights=\"distance\")\n    \n    x_train = xy_train_past[feature_cols+category_cols]\n    x_train_std = scaler.fit_transform(x_train)\n    y_train = xy_train_past['target']\n    \n    # gen test features\n    test, _ = gen_features_49(test, feature_dicts)\n    x_pred = test[feature_cols + category_cols]\n    x_pred_std = scaler.transform(x_pred)\n    \n    neigh.fit(x_train_std, y_train)\n    \n    df_records = pd.concat([df_records, test]) \n                            \n#     这个column 不能drop。。。\n#     df_test = df_test.drop(columns=[\"currently_scored\"])\n#     df_test.fillna(0, inplace=True)\n#     df_test.replace([np.inf, -np.inf], 0, inplace=True)\n    \n#     scaler = StandardScaler()\n#     neigh = KNeighborsRegressor(n_neighbors=50, weights=\"distance\")\n    \n#     used_records = df_records.dropna()\n#     used_records = used_records[used_records[\"date_id\"] >= current_date - 30]\n#     print(len(used_records))\n\n#     std_records = scaler.fit_transform(used_records.dropna()[used_records.columns.difference(['date_id', \"time_id\", \"target\"])])\n#     std_tests = scaler.transform(df_test[df_test.columns.difference(['date_id', \"currently_scored\"])])\n\n#     cur_targets = used_records.loc[:, \"target\"]\n#     neigh.fit(std_records, cur_targets)\n    \n#     df_records = pd.concat([df_records, df_test.loc[:, df_test.columns.isin(df_records.columns)]], ignore_index=True)\n    \n#     feature_cols, category_cols = gen_feature_cols(feature_dicts)\n    \n    # predict target using trained model\n    y_pred = neigh.predict(x_pred_std)\n    y_pred_zs = zero_sum(y_pred, test['bid_size']+test['ask_size'])\n    y_clip = np.clip(y_pred_zs, y_min, y_max)\n    \n    if np.any(np.isnan(y_clip)):\n        df_test.to_csv(\"error_iter.csv\")\n        raise Exception(\"Error! NaN is found in y_clip.\")\n        \n    sample_prediction['target'] = y_clip\n    \n    env.predict(sample_prediction)\n\n    # after 54 timesteps, a new day starts\n    if counter >= 54:\n        print(f\"New Day! Time used: {time() - day_begin:2f}s.\")\n        counter = 0\n        day_begin = time()\n        cache = pd.DataFrame()\n        \n        # kick out the oldest date\n        recorded_dates = df_records['date_id'].unique().tolist()\n        recorded_dates.sort()\n        df_records = df_records[df_records['date_id'].isin(recorded_dates[1:])]\n    else:\n        counter += 1\n        \n\n            ","metadata":{"execution":{"iopub.status.busy":"2023-12-12T12:39:03.027739Z","iopub.execute_input":"2023-12-12T12:39:03.028708Z","iopub.status.idle":"2023-12-12T12:43:10.568208Z","shell.execute_reply.started":"2023-12-12T12:39:03.028656Z","shell.execute_reply":"2023-12-12T12:43:10.566777Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\ncurr_date 478\n549999\nTargets revealed for day [477]\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\ncurr_date 478\nNew Day! Time used: 78.434880s.\ncurr_date 479\n549999\nTargets revealed for day [478]\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\ncurr_date 479\nNew Day! Time used: 82.581657s.\ncurr_date 480\n549999\nTargets revealed for day [479]\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\ncurr_date 480\nNew Day! Time used: 85.937773s.\n","output_type":"stream"}]},{"cell_type":"code","source":"df_submission = pd.read_csv('submission.csv')\ndf_submission","metadata":{"execution":{"iopub.status.busy":"2023-12-12T12:43:10.570006Z","iopub.execute_input":"2023-12-12T12:43:10.570495Z","iopub.status.idle":"2023-12-12T12:43:10.625231Z","shell.execute_reply.started":"2023-12-12T12:43:10.570453Z","shell.execute_reply":"2023-12-12T12:43:10.623770Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"            row_id    target\n0          478_0_0 -1.027586\n1          478_0_1  1.597115\n2          478_0_2  9.376052\n3          478_0_3  0.472221\n4          478_0_4  0.611340\n...            ...       ...\n32995  480_540_195 -0.763817\n32996  480_540_196 -1.388240\n32997  480_540_197  1.231299\n32998  480_540_198  0.974671\n32999  480_540_199 -1.305015\n\n[33000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>478_0_0</td>\n      <td>-1.027586</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>478_0_1</td>\n      <td>1.597115</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>478_0_2</td>\n      <td>9.376052</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>478_0_3</td>\n      <td>0.472221</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>478_0_4</td>\n      <td>0.611340</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32995</th>\n      <td>480_540_195</td>\n      <td>-0.763817</td>\n    </tr>\n    <tr>\n      <th>32996</th>\n      <td>480_540_196</td>\n      <td>-1.388240</td>\n    </tr>\n    <tr>\n      <th>32997</th>\n      <td>480_540_197</td>\n      <td>1.231299</td>\n    </tr>\n    <tr>\n      <th>32998</th>\n      <td>480_540_198</td>\n      <td>0.974671</td>\n    </tr>\n    <tr>\n      <th>32999</th>\n      <td>480_540_199</td>\n      <td>-1.305015</td>\n    </tr>\n  </tbody>\n</table>\n<p>33000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}