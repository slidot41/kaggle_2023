{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys, warnings\n",
    "from feature_engineer import *\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5237892, 17)\n",
      "Trading days: 481\n",
      "Stocks: 200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.50</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>8493.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.029704</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166603.91</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>3233.04</td>\n",
       "      <td>1.000660</td>\n",
       "      <td>20605.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.519986</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302879.87</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>37956.00</td>\n",
       "      <td>1.000298</td>\n",
       "      <td>18995.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.389950</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11917682.27</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389745.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2324.90</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>479032.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.010200</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>447549.96</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>16485.54</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>434.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.349849</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0         0        0                  0      3180602.69   \n",
       "1         1        0                  0       166603.91   \n",
       "2         2        0                  0       302879.87   \n",
       "3         3        0                  0     11917682.27   \n",
       "4         4        0                  0       447549.96   \n",
       "\n",
       "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                        1         0.999812   13380276.64        NaN   \n",
       "1                       -1         0.999896    1642214.25        NaN   \n",
       "2                       -1         0.999561    1819368.03        NaN   \n",
       "3                       -1         1.000171   18389745.62        NaN   \n",
       "4                       -1         0.999532   17860614.95        NaN   \n",
       "\n",
       "   near_price  bid_price  bid_size  ask_price   ask_size  wap    target  \\\n",
       "0         NaN   0.999812  60651.50   1.000026    8493.03  1.0 -3.029704   \n",
       "1         NaN   0.999896   3233.04   1.000660   20605.09  1.0 -5.519986   \n",
       "2         NaN   0.999403  37956.00   1.000298   18995.00  1.0 -8.389950   \n",
       "3         NaN   0.999999   2324.90   1.000214  479032.40  1.0 -4.010200   \n",
       "4         NaN   0.999394  16485.54   1.000016     434.10  1.0 -7.349849   \n",
       "\n",
       "   time_id row_id  \n",
       "0        0  0_0_0  \n",
       "1        0  0_0_1  \n",
       "2        0  0_0_2  \n",
       "3        0  0_0_3  \n",
       "4        0  0_0_4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/shiyili/projects/kaggle/train.csv\")\n",
    "df = df[~df['target'].isnull()] \n",
    "\n",
    "print(df.shape)\n",
    "print(f\"Trading days: {df['date_id'].nunique()}\")\n",
    "print(f\"Stocks: {df['stock_id'].nunique()}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : (4742893, 17), valid : (494999, 17)\n"
     ]
    }
   ],
   "source": [
    "split_day = 435\n",
    "df_train = df[df[\"date_id\"] <= split_day]\n",
    "df_valid = df[df[\"date_id\"] > split_day]\n",
    "print(f\"train : {df_train.shape}, valid : {df_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_stock_id_feats = {\n",
    "    \"median_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].median() + df_train.groupby(\"stock_id\")[\"ask_size\"].median(),\n",
    "    \"std_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].std() + df_train.groupby(\"stock_id\")[\"ask_size\"].std(),\n",
    "    \"ptp_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].max() - df_train.groupby(\"stock_id\")[\"bid_size\"].min(),\n",
    "    \"median_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].median() + df_train.groupby(\"stock_id\")[\"ask_price\"].median(),\n",
    "    \"std_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].std() + df_train.groupby(\"stock_id\")[\"ask_price\"].std(),\n",
    "    \"ptp_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].max() - df_train.groupby(\"stock_id\")[\"ask_price\"].min(),\n",
    "    }\n",
    "\n",
    "\n",
    "df_train_feats = generate_all_features(df_train, global_stock_id_feats)\n",
    "print(\"Build Train Feats Finished.\")\n",
    "df_valid_feats = generate_all_features(df_valid, global_stock_id_feats)\n",
    "print(\"Build Valid Feats Finished.\")\n",
    "\n",
    "df_valid_feats = reduce_mem_usage(df_valid_feats)\n",
    "df_train_feats = reduce_mem_usage(df_train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feats.to_csv(\"train_feats.csv\", index=False)\n",
    "df_valid_feats.to_csv(\"valid_feats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feats['row_id'] = \\\n",
    "    df_train_feats['date_id'].astype(str) + '_' + df_train_feats['stock_id'].astype(str) + \"_\" + df_train_feats['seconds_in_bucket'].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feats = df_train_feats.join(df_train[['row_id', 'target']], on='row_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feats['row_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['row_id', 'target']]\n",
    "df['row_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape, df_train_feats.shape \n",
    "# df_train_feats['target'] = df['target']\n",
    "df_train_feats.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Fully Connected Neural Network Model with 2 hidden layers\n",
    "# first layer is a non-linear layer with 60 neurons\n",
    "# second layer is a linear layer with 1 neuron\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, SGD\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, df, feats, target):\n",
    "        self.feats = feats\n",
    "        self.target = target\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feats = torch.tensor(self.feats[idx], dtype=torch.float)\n",
    "        target = torch.tensor(self.target[idx], dtype=torch.float)\n",
    "        return feats, target\n",
    "    \n",
    "class StockModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(StockModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for feats, target in train_loader:\n",
    "        feats = feats.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(feats)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    return train_loss / len(train_loader)\n",
    "\n",
    "def valid(model, valid_loader, criterion):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    preds = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for feats, target in valid_loader:\n",
    "            feats = feats.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(feats)\n",
    "            loss = criterion(output, target)\n",
    "            valid_loss += loss.item()\n",
    "            preds.append(output.cpu().numpy())\n",
    "            targets.append(target.cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    targets = np.concatenate(targets)\n",
    "    return valid_loss / len(valid_loader), preds, targets\n",
    "\n",
    "def train_loop(model, train_loader, valid_loader, optimizer, criterion, epochs):\n",
    "    best_loss = np.inf\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(model, train_loader, optimizer, criterion)\n",
    "        valid_loss, preds, targets = valid(model, valid_loader, criterion)\n",
    "        rmse = np.sqrt(mean_squared_error(targets, preds))\n",
    "        print(f\"Epoch {epoch+1} - train_loss: {train_loss:.4f}  valid_loss: {valid_loss:.4f}  rmse: {rmse:.4f}\")\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            torch.save(model.state_dict(), \"model.pt\")\n",
    "            print(\"Save Model.\")\n",
    "\n",
    "df_train_feats = pd.read_csv(\"train_feats.csv\")\n",
    "df_train_feats = df_train_feats[~df_train_feats['target'].isnull()]\n",
    "df_train_feats = df_train_feats.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "df_train_feats.head()\n",
    "\n",
    "df_valid_feats = pd.read_csv(\"valid_feats.csv\")\n",
    "\n",
    "df_valid_feats = df_valid_feats[~df_valid_feats['target'].isnull()]\n",
    "\n",
    "df_valid_feats = df_valid_feats.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "df_valid_feats.head()\n",
    "\n",
    "feats = [col for col in df_train_feats.columns if col not in [\"target\", \"date_id\", \"stock_id\"]]\n",
    "\n",
    "target = df_train_feats[\"target\"].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(df_train_feats[feats])\n",
    "\n",
    "df_train_feats[feats] = scaler.transform(df_train_feats[feats])\n",
    "\n",
    "df_valid_feats[feats] = scaler.transform(df_valid_feats[feats])\n",
    "\n",
    "train_dataset = StockDataset(df_train_feats, df_train_feats[feats].values, target)\n",
    "\n",
    "valid_dataset = StockDataset(df_valid_feats, df_valid_feats[feats].values, df_valid_feats[\"target\"].values)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = StockModel(len(feats), 60).to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_loop(model, train_loader, valid_loader, optimizer, criterion, epochs=100)\n",
    "\n",
    "df_valid_feats = pd.read_csv(\"valid_feats.csv\")\n",
    "\n",
    "df_valid_feats = df_valid_feats[~df_valid_feats['target'].isnull()]\n",
    "\n",
    "df_valid_feats = df_valid_feats.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "df_valid_feats.head()\n",
    "\n",
    "feats = [col for col in df_valid_feats.columns if col not in [\"target\", \"date_id\", \"stock_id\"]]\n",
    "\n",
    "target = df_valid_feats[\"target\"].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(df_valid_feats[feats])\n",
    "\n",
    "df_valid_feats[feats] = scaler.transform(df_valid_feats[feats])\n",
    "\n",
    "valid_dataset = StockDataset(df_valid_feats, df_valid_feats[feats].values, df_valid_feats[\"target\"].values)\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = StockModel(len(feats), 60).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"model.pt\"))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "valid_loss, preds, targets = valid(model, valid_loader, criterion)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(targets, preds))\n",
    "\n",
    "print(f\"valid_loss: {valid_loss:.4f}  rmse: {rmse:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = df.groupby(['date_id', 'stock_id'])\n",
    "\n",
    "# calculate wap change per stock per day\n",
    "df['wap_chg_1'] = group['wap'].diff() / group['wap'].shift(1) * 100\n",
    "df['imb_size_change'] = group['imb_size_with_flag'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_hist = df[(df.stock_id==0)]['imb_size_change']\n",
    "to_hist = to_hist[(~to_hist.isnull()) & (to_hist != np.inf) & (to_hist != -np.inf)]\n",
    "plt.hist(to_hist,  bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot wap change v.s. imbalance size change\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "sub_df = df[(df.stock_id==0)&(df.date_id==0)]\n",
    "ax.scatter(sub_df['imb_size_change'], sub_df['wap_chg_1'], s=1)\n",
    "ax.set_xlabel('Imbalance Size Change (%)')\n",
    "ax.set_ylabel('WAP Change (%)')\n",
    "ax.set_title('WAP Change v.s. Imbalance Size Change')\n",
    "# ax.set_xlim([-100, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_market_calendars as mcal\n",
    "\n",
    "four_witches = [\n",
    "    '20210917', '20211217',\n",
    "    '20220318', '20220617', '20220916', '20221216', \n",
    "    '20230317', '20230616', '20230915', '20231215'\n",
    "    ]\n",
    "\n",
    "fomc_dates = [\n",
    "    '20210827', '20211103', '20211215',\n",
    "    '20220126', '20220316', '20220427', '20220615', '20220727', '20220921', '20221102', '20221214',\n",
    "    '20230125', '20230315', '20230426', '20230614', '20230726', '20230920', '20231101', '20231213'\n",
    "    ]\n",
    "\n",
    "# start date is 2021-08-02 in New York time\n",
    "start_date = pd.to_datetime('20210802', format='%Y%m%d')\n",
    "start_date = start_date.tz_localize('America/New_York')\n",
    "\n",
    "# count trading days using pandas_market_calendars\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "trading_days = nyse.schedule(start_date=start_date, end_date='20231231')\n",
    "trading_days = trading_days.reset_index()\n",
    "trading_days['date_id'] = trading_days['market_close'].dt.strftime('%Y%m%d')\n",
    "trading_days = trading_days[['date_id', 'market_close']]\n",
    "\n",
    "trading_days['four_witches'] = trading_days['date_id'].isin(four_witches)\n",
    "trading_days['fomc'] = trading_days['date_id'].isin(fomc_dates)\n",
    "\n",
    "trading_days['days_count'] = trading_days.index\n",
    "\n",
    "four_witches_days = trading_days[trading_days['four_witches']]\n",
    "fomc_days = trading_days[trading_days['fomc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
