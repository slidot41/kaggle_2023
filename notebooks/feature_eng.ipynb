{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys, warnings\n",
    "from feature_engineer import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/shiyili/projects/kaggle/train.csv\")\n",
    "df = df[~df['target'].isnull()] \n",
    "\n",
    "print(df.shape)\n",
    "print(f\"Trading days: {df['date_id'].nunique()}\")\n",
    "print(f\"Stocks: {df['stock_id'].nunique()}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_day = 435\n",
    "df_train = df[df[\"date_id\"] <= split_day]\n",
    "df_valid = df[df[\"date_id\"] > split_day]\n",
    "print(f\"train : {df_train.shape}, valid : {df_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_stock_id_feats = {\n",
    "    \"median_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].median() + df_train.groupby(\"stock_id\")[\"ask_size\"].median(),\n",
    "    \"std_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].std() + df_train.groupby(\"stock_id\")[\"ask_size\"].std(),\n",
    "    \"ptp_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].max() - df_train.groupby(\"stock_id\")[\"bid_size\"].min(),\n",
    "    \"median_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].median() + df_train.groupby(\"stock_id\")[\"ask_price\"].median(),\n",
    "    \"std_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].std() + df_train.groupby(\"stock_id\")[\"ask_price\"].std(),\n",
    "    \"ptp_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].max() - df_train.groupby(\"stock_id\")[\"ask_price\"].min(),\n",
    "    }\n",
    "\n",
    "\n",
    "df_train_feats = generate_all_features(df_train, global_stock_id_feats)\n",
    "print(\"Build Train Feats Finished.\")\n",
    "df_valid_feats = generate_all_features(df_valid, global_stock_id_feats)\n",
    "print(\"Build Valid Feats Finished.\")\n",
    "\n",
    "df_valid_feats = reduce_mem_usage(df_valid_feats)\n",
    "df_train_feats = reduce_mem_usage(df_train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feats.to_csv(\"train_feats.csv\", index=False)\n",
    "df_valid_feats.to_csv(\"valid_feats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Fully Connected Neural Network Model with 2 hidden layers\n",
    "# first layer is a non-linear layer with 60 neurons\n",
    "# second layer is a linear layer with 1 neuron\n",
    "\n",
    "\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, df, feats, target):\n",
    "        self.feats = feats\n",
    "        self.target = target\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feats = torch.tensor(self.feats[idx], dtype=torch.float)\n",
    "        target = torch.tensor(self.target[idx], dtype=torch.float)\n",
    "        return feats, target\n",
    "    \n",
    "class StockModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(StockModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for feats, target in train_loader:\n",
    "        feats = feats.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(feats)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    return train_loss / len(train_loader)\n",
    "\n",
    "def valid(model, valid_loader, criterion):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    preds = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for feats, target in valid_loader:\n",
    "            feats = feats.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(feats)\n",
    "            loss = criterion(output, target)\n",
    "            valid_loss += loss.item()\n",
    "            preds.append(output.cpu().numpy())\n",
    "            targets.append(target.cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    targets = np.concatenate(targets)\n",
    "    return valid_loss / len(valid_loader), preds, targets\n",
    "\n",
    "def train_loop(model, train_loader, valid_loader, optimizer, criterion, epochs):\n",
    "    best_loss = np.inf\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(model, train_loader, optimizer, criterion)\n",
    "        valid_loss, preds, targets = valid(model, valid_loader, criterion)\n",
    "        rmse = np.sqrt(mean_squared_error(targets, preds))\n",
    "        print(f\"Epoch {epoch+1} - train_loss: {train_loss:.4f}  valid_loss: {valid_loss:.4f}  rmse: {rmse:.4f}\")\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            torch.save(model.state_dict(), \"model.pt\")\n",
    "            print(\"Save Model.\")\n",
    "\n",
    "# df_train_feats = pd.read_csv(\"train_feats.csv\")\n",
    "# df_train_feats = df_train_feats[~df_train_feats['target'].isnull()]\n",
    "# df_train_feats = df_train_feats.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# df_train_feats.head()\n",
    "\n",
    "# df_valid_feats = pd.read_csv(\"valid_feats.csv\")\n",
    "\n",
    "# df_valid_feats = df_valid_feats[~df_valid_feats['target'].isnull()]\n",
    "\n",
    "# df_valid_feats = df_valid_feats.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# df_valid_feats.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [col for col in df_train_feats.columns if col not in [\"target\", \"date_id\", \"stock_id\"]]\n",
    "\n",
    "train_feats = df_train_feats[feats]\n",
    "valid_feats = df_valid_feats[feats]\n",
    "\n",
    "train_target = df_train_feats[\"target\"]\n",
    "valid_target = df_valid_feats[\"target\"]\n",
    "\n",
    "train_feats = train_feats.fillna(0)\n",
    "valid_feats = valid_feats.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_train = StandardScaler()\n",
    "scaler_train.fit(train_feats)\n",
    "train_feats = scaler_train.transform(train_feats)\n",
    "\n",
    "scaler_valid = StandardScaler()\n",
    "scaler_valid.fit(valid_feats)\n",
    "valid_feats = scaler_valid.transform(valid_feats)\n",
    "\n",
    "train_dataset = StockDataset()\n",
    "\n",
    "\n",
    "df_valid_feats[feats] = scaler.transform(df_valid_feats[feats])\n",
    "\n",
    "valid_dataset = StockDataset(df_valid_feats, df_valid_feats[feats].values, df_valid_feats[\"target\"].values)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = StockModel(len(feats), 60).to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_loop(model, train_loader, valid_loader, optimizer, criterion, epochs=100)\n",
    "\n",
    "df_valid_feats = pd.read_csv(\"valid_feats.csv\")\n",
    "\n",
    "df_valid_feats = df_valid_feats[~df_valid_feats['target'].isnull()]\n",
    "\n",
    "df_valid_feats = df_valid_feats.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "df_valid_feats.head()\n",
    "\n",
    "feats = [col for col in df_valid_feats.columns if col not in [\"target\", \"date_id\", \"stock_id\"]]\n",
    "\n",
    "target = df_valid_feats[\"target\"].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(df_valid_feats[feats])\n",
    "\n",
    "df_valid_feats[feats] = scaler.transform(df_valid_feats[feats])\n",
    "\n",
    "valid_dataset = StockDataset(df_valid_feats, df_valid_feats[feats].values, df_valid_feats[\"target\"].values)\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = StockModel(len(feats), 60).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"model.pt\"))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "valid_loss, preds, targets = valid(model, valid_loader, criterion)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(targets, preds))\n",
    "\n",
    "print(f\"valid_loss: {valid_loss:.4f}  rmse: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = df.groupby(['date_id', 'stock_id'])\n",
    "\n",
    "# calculate wap change per stock per day\n",
    "df['wap_chg_1'] = group['wap'].diff() / group['wap'].shift(1) * 100\n",
    "df['imb_size_change'] = group['imb_size_with_flag'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_hist = df[(df.stock_id==0)]['imb_size_change']\n",
    "to_hist = to_hist[(~to_hist.isnull()) & (to_hist != np.inf) & (to_hist != -np.inf)]\n",
    "plt.hist(to_hist,  bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot wap change v.s. imbalance size change\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "sub_df = df[(df.stock_id==0)&(df.date_id==0)]\n",
    "ax.scatter(sub_df['imb_size_change'], sub_df['wap_chg_1'], s=1)\n",
    "ax.set_xlabel('Imbalance Size Change (%)')\n",
    "ax.set_ylabel('WAP Change (%)')\n",
    "ax.set_title('WAP Change v.s. Imbalance Size Change')\n",
    "# ax.set_xlim([-100, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_market_calendars as mcal\n",
    "\n",
    "four_witches = [\n",
    "    '20210917', '20211217',\n",
    "    '20220318', '20220617', '20220916', '20221216', \n",
    "    '20230317', '20230616', '20230915', '20231215'\n",
    "    ]\n",
    "\n",
    "fomc_dates = [\n",
    "    '20210827', '20211103', '20211215',\n",
    "    '20220126', '20220316', '20220427', '20220615', '20220727', '20220921', '20221102', '20221214',\n",
    "    '20230125', '20230315', '20230426', '20230614', '20230726', '20230920', '20231101', '20231213'\n",
    "    ]\n",
    "\n",
    "# start date is 2021-08-02 in New York time\n",
    "start_date = pd.to_datetime('20210802', format='%Y%m%d')\n",
    "start_date = start_date.tz_localize('America/New_York')\n",
    "\n",
    "# count trading days using pandas_market_calendars\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "trading_days = nyse.schedule(start_date=start_date, end_date='20231231')\n",
    "trading_days = trading_days.reset_index()\n",
    "trading_days['date_id'] = trading_days['market_close'].dt.strftime('%Y%m%d')\n",
    "trading_days = trading_days[['date_id', 'market_close']]\n",
    "\n",
    "trading_days['four_witches'] = trading_days['date_id'].isin(four_witches)\n",
    "trading_days['fomc'] = trading_days['date_id'].isin(fomc_dates)\n",
    "\n",
    "trading_days['days_count'] = trading_days.index\n",
    "\n",
    "four_witches_days = trading_days[trading_days['four_witches']]\n",
    "fomc_days = trading_days[trading_days['fomc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
