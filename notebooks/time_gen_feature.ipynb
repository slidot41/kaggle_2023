{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import talib as ta\n",
    "from itertools import combinations\n",
    "\n",
    "from time import time \n",
    "from create_feature import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5237892, 17)\n",
      "Trading days: 481\n",
      "Stocks: 200\n"
     ]
    }
   ],
   "source": [
    "feature_dicts = {\n",
    "        'prices': [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"],\n",
    "        'sizes':  [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"],\n",
    "        \"category\": [\"stock_id\", \"seconds_in_bucket\", 'imbalance_buy_sell_flag']\n",
    "    }\n",
    "\n",
    "csv_train = \"/home/lishi/projects/Competition/kaggle_2023/data/train.csv\"\n",
    "df = pd.read_csv(csv_train)\n",
    "df = df[~df['target'].isnull()] \n",
    "\n",
    "print(df.shape)\n",
    "print(f\"Trading days: {df['date_id'].nunique()}\")\n",
    "print(f\"Stocks: {df['stock_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, v1_features = gen_v1_features(df, feature_dicts['prices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_feat_cols = feature_dicts['prices'] + feature_dicts['sizes'] + v1_features\n",
    "\n",
    "df, v2_features = gen_v2_features(df, v2_feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_stock = df.groupby(['date_id', 'stock_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_features = ['imbalance_with_flag', 'wap', 'matched_imbalance']\n",
    "relative_change = group_by_stock[pct_features].pct_change(1, fill_method=None).add_prefix('pct_')\n",
    "df_v3 = pd.concat([df, relative_change], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v3 = reduce_mem_usage(df_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_features = [\n",
    "        'ask_size',\n",
    "        # 'bid_size',\n",
    "        # 'imbalance_with_flag',\n",
    "        # 'liquidity_imbalance',\n",
    "        # 'matched_imbalance',\n",
    "        # 'reference_price_ask_price_imbalance',\n",
    "        # 'reference_price_bid_price_imbalance',\n",
    "        # 'reference_price_wap_imbalance',\n",
    "        # 'far_price_near_price_imbalance',\n",
    "        ]\n",
    "    \n",
    "df_rolling = group_by_stock[rolling_features].rolling(5).agg(['mean', 'std', 'max', 'min']).reset_index()\n",
    "stats_cols = [f\"{c[1]}_{c[0]}_5\" for c in df_rolling.columns[2:]]\n",
    "df_rolling.columns = ['date_id', 'stock_id'] + stats_cols\n",
    "df_rolling.set_index('_level_2_5', inplace=True)\n",
    "df_rolling.drop(columns=['date_id', 'stock_id'], inplace=True)\n",
    "\n",
    "df_v3 = df.merge(df_rolling, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_features = [\n",
    "        'ask_size',\n",
    "        # 'bid_size',\n",
    "        # 'imbalance_with_flag',\n",
    "        # 'liquidity_imbalance',\n",
    "        # 'matched_imbalance',\n",
    "        # 'reference_price_ask_price_imbalance',\n",
    "        # 'reference_price_bid_price_imbalance',\n",
    "        # 'reference_price_wap_imbalance',\n",
    "        # 'far_price_near_price_imbalance',\n",
    "        ]\n",
    "    \n",
    "df_rolling = group_by_stock[rolling_features].rolling(5).agg(['mean', 'std', 'max', 'min']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_cols = [f\"{c[1]}_{c[0]}_5\" for c in df_rolling.columns[2:]]\n",
    "df_rolling.columns = ['date_id', 'stock_id'] + stats_cols\n",
    "df_rolling.set_index('_level_2_5', inplace=True)\n",
    "df_rolling.drop(columns=['date_id', 'stock_id'], inplace=True)\n",
    "\n",
    "df_v3 = df.merge(df_rolling, left_index=True, right_index=True, how='left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
