{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "023a8eae",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-06T09:31:15.405655Z",
     "iopub.status.busy": "2023-12-06T09:31:15.405242Z",
     "iopub.status.idle": "2023-12-06T09:31:15.430327Z",
     "shell.execute_reply": "2023-12-06T09:31:15.429159Z"
    },
    "papermill": {
     "duration": 0.034342,
     "end_time": "2023-12-06T09:31:15.433227",
     "exception": false,
     "start_time": "2023-12-06T09:31:15.398885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current DIR:  /kaggle/working\n",
      "/kaggle/input/optiver-trading-at-the-close/public_timeseries_testing_util.py\n",
      "/kaggle/input/optiver-trading-at-the-close/train.csv\n",
      "/kaggle/input/optiver-trading-at-the-close/example_test_files/sample_submission.csv\n",
      "/kaggle/input/optiver-trading-at-the-close/example_test_files/revealed_targets.csv\n",
      "/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv\n",
      "/kaggle/input/optiver-trading-at-the-close/optiver2023/competition.cpython-310-x86_64-linux-gnu.so\n",
      "/kaggle/input/optiver-trading-at-the-close/optiver2023/__init__.py\n",
      "/kaggle/input/feature-engineer/feature_engineer.py\n",
      "/kaggle/input/model-fcn-2layer/model_fcn_2layer.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Current DIR: \", os.getcwd())\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45b0a86e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-06T09:31:15.446271Z",
     "iopub.status.busy": "2023-12-06T09:31:15.445779Z",
     "iopub.status.idle": "2023-12-06T09:31:16.561805Z",
     "shell.execute_reply": "2023-12-06T09:31:16.560206Z"
    },
    "papermill": {
     "duration": 1.125222,
     "end_time": "2023-12-06T09:31:16.564794",
     "exception": false,
     "start_time": "2023-12-06T09:31:15.439572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! cp /kaggle/input/feature-engineer/feature_engineer.py /kaggle/working/feature_engineer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4070f82a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-06T09:31:16.576265Z",
     "iopub.status.busy": "2023-12-06T09:31:16.575868Z",
     "iopub.status.idle": "2023-12-06T09:31:23.691987Z",
     "shell.execute_reply": "2023-12-06T09:31:23.690996Z"
    },
    "papermill": {
     "duration": 7.125579,
     "end_time": "2023-12-06T09:31:23.694741",
     "exception": false,
     "start_time": "2023-12-06T09:31:16.569162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optiver2023\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from feature_engineer import * \n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from torch.optim import Adam, SGD\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03d92825",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-06T09:31:23.705171Z",
     "iopub.status.busy": "2023-12-06T09:31:23.704634Z",
     "iopub.status.idle": "2023-12-06T09:31:23.709938Z",
     "shell.execute_reply": "2023-12-06T09:31:23.708799Z"
    },
    "papermill": {
     "duration": 0.01316,
     "end_time": "2023-12-06T09:31:23.712156",
     "exception": false,
     "start_time": "2023-12-06T09:31:23.698996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb5e8886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-06T09:31:23.722943Z",
     "iopub.status.busy": "2023-12-06T09:31:23.721997Z",
     "iopub.status.idle": "2023-12-06T09:31:23.732281Z",
     "shell.execute_reply": "2023-12-06T09:31:23.731482Z"
    },
    "papermill": {
     "duration": 0.018201,
     "end_time": "2023-12-06T09:31:23.734710",
     "exception": false,
     "start_time": "2023-12-06T09:31:23.716509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, features, target):\n",
    "        self.y = target\n",
    "        self.X = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx, :], self.y[idx]\n",
    "    \n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        output = self.linear_relu_stack(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "# define a function to predict the target\n",
    "def predict(model, pred_loader):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in pred_loader:\n",
    "            output = model(data.float())\n",
    "            y_pred.extend(output.tolist())\n",
    "            \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85d7c4d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-06T09:31:23.745304Z",
     "iopub.status.busy": "2023-12-06T09:31:23.744707Z",
     "iopub.status.idle": "2023-12-06T09:31:23.829600Z",
     "shell.execute_reply": "2023-12-06T09:31:23.828438Z"
    },
    "papermill": {
     "duration": 0.093246,
     "end_time": "2023-12-06T09:31:23.832269",
     "exception": false,
     "start_time": "2023-12-06T09:31:23.739023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "\n",
    "model.load_state_dict(torch.load(\"/kaggle/input/model-fcn-2layer/model_fcn_2layer.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae39710",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-06T09:31:23.843514Z",
     "iopub.status.busy": "2023-12-06T09:31:23.843095Z",
     "iopub.status.idle": "2023-12-06T09:33:13.107358Z",
     "shell.execute_reply": "2023-12-06T09:33:13.106001Z"
    },
    "papermill": {
     "duration": 109.273003,
     "end_time": "2023-12-06T09:33:13.110241",
     "exception": false,
     "start_time": "2023-12-06T09:31:23.837238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n",
      "10 qps: 0.8892535448074341\n",
      "The code will take approximately 1.0191 hours to reason about\n",
      "20 qps: 0.7506235003471374\n",
      "The code will take approximately 0.8602 hours to reason about\n",
      "30 qps: 0.7147401094436645\n",
      "The code will take approximately 0.8191 hours to reason about\n",
      "40 qps: 0.6962623953819275\n",
      "The code will take approximately 0.7979 hours to reason about\n",
      "50 qps: 0.6850412654876709\n",
      "The code will take approximately 0.7851 hours to reason about\n",
      "60 qps: 0.6777941068013509\n",
      "The code will take approximately 0.7768 hours to reason about\n",
      "70 qps: 0.6723435265677316\n",
      "The code will take approximately 0.7705 hours to reason about\n",
      "80 qps: 0.6688307762145996\n",
      "The code will take approximately 0.7665 hours to reason about\n",
      "90 qps: 0.6654219680362278\n",
      "The code will take approximately 0.7626 hours to reason about\n",
      "100 qps: 0.662209460735321\n",
      "The code will take approximately 0.7589 hours to reason about\n",
      "110 qps: 0.6603009484030984\n",
      "The code will take approximately 0.7567 hours to reason about\n",
      "120 qps: 0.6586016277472179\n",
      "The code will take approximately 0.7548 hours to reason about\n",
      "130 qps: 0.6577398336850679\n",
      "The code will take approximately 0.7538 hours to reason about\n",
      "140 qps: 0.655995295728956\n",
      "The code will take approximately 0.7518 hours to reason about\n",
      "150 qps: 0.655593581199646\n",
      "The code will take approximately 0.7513 hours to reason about\n",
      "160 qps: 0.6552350029349328\n",
      "The code will take approximately 0.7509 hours to reason about\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "cache = pd.DataFrame()\n",
    "qps = []\n",
    "\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "    now_time = time()\n",
    "    \n",
    "    cache = pd.concat([cache, test], ignore_index=True, axis=0)\n",
    "    \n",
    "    global_stock_id_feats = {\n",
    "        \"median_size\": cache.groupby(\"stock_id\")[\"bid_size\"].median() + cache.groupby(\"stock_id\")[\"ask_size\"].median(),\n",
    "        \"std_size\": cache.groupby(\"stock_id\")[\"bid_size\"].std() + cache.groupby(\"stock_id\")[\"ask_size\"].std(),\n",
    "        \"ptp_size\": cache.groupby(\"stock_id\")[\"bid_size\"].max() - cache.groupby(\"stock_id\")[\"bid_size\"].min(),\n",
    "        \"median_price\": cache.groupby(\"stock_id\")[\"bid_price\"].median() + cache.groupby(\"stock_id\")[\"ask_price\"].median(),\n",
    "        \"std_price\": cache.groupby(\"stock_id\")[\"bid_price\"].std() + cache.groupby(\"stock_id\")[\"ask_price\"].std(),\n",
    "        \"ptp_price\": cache.groupby(\"stock_id\")[\"bid_price\"].max() - cache.groupby(\"stock_id\")[\"ask_price\"].min(),\n",
    "        }\n",
    "    \n",
    "    # üîÑ If not the first iteration, limit the cache to the last 21 rows for each stock\n",
    "    if counter > 0:\n",
    "        cache = cache.groupby(['stock_id']).tail(21).sort_values(by=['date_id', 'seconds_in_bucket', 'stock_id']).reset_index(drop=True)\n",
    "    \n",
    "    # üìä Generate features based on the updated cache\n",
    "    df_feat = generate_all_features(cache, global_stock_id_feats)[-len(test):]\n",
    "    \n",
    "    feat_cols = [col for col in df_feat.columns if col not in ['target', 'date_id', 'dow', 'time_id', 'currently_scored']]\n",
    "    df_feat = df_feat[feat_cols]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    standarize_cols = [col for col in feat_cols if col not in ['stock_id', 'seconds_in_bucket', 'imbalance_buy_sell_flag', 'session_label', 'seconds', 'minute']]\n",
    "    df_feat[standarize_cols] = scaler.fit_transform(df_feat[standarize_cols])\n",
    "    \n",
    "    target = np.ones(df_feat.shape[0])\n",
    "    pred_dataset = MyDataset(\n",
    "        torch.from_numpy(df_feat.values), torch.from_numpy(target)\n",
    "    )\n",
    "    \n",
    "    prediction_loader = DataLoader(pred_dataset, batch_size=2048, shuffle=False)\n",
    "    y_pred = predict(model, prediction_loader)\n",
    "\n",
    "#     # üìä Generate predictions for each model and calculate the weighted average\n",
    "#     lgb_predictions = np.zeros(len(test))\n",
    "#     for model, weight in zip(models, model_weights):\n",
    "#         lgb_predictions += weight * model.predict(feat)\n",
    "\n",
    "#     # üßÆ Adjust predictions using the zero_sum function\n",
    "#     lgb_predictions = zero_sum(lgb_predictions, test['bid_size'] + test['ask_size'])\n",
    "#     clipped_predictions = np.clip(lgb_predictions, y_min, y_max)  # üìè Clip predictions within a specified range\n",
    "    \n",
    "    sample_prediction['target'] = y_pred\n",
    "    env.predict(sample_prediction)  # üìà Submit predictions to the environment\n",
    "    counter += 1\n",
    "    qps.append(time() - now_time)\n",
    "\n",
    "    # üîÑ Print the average queries per second every 10 iterations\n",
    "    if counter % 10 == 0:\n",
    "        print(counter, 'qps:', np.mean(qps))\n",
    "\n",
    "        time_cost = 1.146 * np.mean(qps)\n",
    "        print(f\"The code will take approximately {np.round(time_cost, 4)} hours to reason about\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c03bf1",
   "metadata": {
    "papermill": {
     "duration": 0.005964,
     "end_time": "2023-12-06T09:33:13.122440",
     "exception": false,
     "start_time": "2023-12-06T09:33:13.116476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bad103",
   "metadata": {
    "papermill": {
     "duration": 0.005767,
     "end_time": "2023-12-06T09:33:13.134434",
     "exception": false,
     "start_time": "2023-12-06T09:33:13.128667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7056235,
     "sourceId": 57891,
     "sourceType": "competition"
    },
    {
     "datasetId": 4076386,
     "sourceId": 7076964,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4076391,
     "sourceId": 7076969,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 123.58529,
   "end_time": "2023-12-06T09:33:15.426173",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-06T09:31:11.840883",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
